import os
import pandas as pd
from docx import Document
from typing import List, Dict, Any
from langchain_text_splitters import RecursiveCharacterTextSplitter
from pypdf import PdfReader
from src.core.logger import logger
from src.clients import VectorClient, GroqClient

class KnowledgeService:
    """
    Cemil'in 'Bilgi KÃ¼pÃ¼' (RAG). DÃ¶kÃ¼manlarÄ± iÅŸler ve sorularÄ± yanÄ±tlar.
    Tamamen Ã¼cretsiz ve limit-free yapÄ±dadÄ±r.
    """

    def __init__(self, vector_client: VectorClient, groq_client: GroqClient):
        self.vector = vector_client
        self.groq = groq_client
        self.splitter = RecursiveCharacterTextSplitter(
            chunk_size=700,
            chunk_overlap=100
        )

    async def process_knowledge_base(self, folder_path: str = "knowledge_base"):
        """Belirtilen klasÃ¶rdeki dÃ¶kÃ¼manlarÄ± okur ve indekse ekler."""
        if not os.path.exists(folder_path):
            os.makedirs(folder_path)
            logger.warning(f"[!] {folder_path} bulunamadÄ±, boÅŸ bir tane oluÅŸturuldu.")
            return

        all_texts = []
        all_metadata = []

        for filename in os.listdir(folder_path):
            file_path = os.path.join(folder_path, filename)
            text = ""
            
            try:
                # PDF Ä°ÅŸleme
                if filename.endswith(".pdf"):
                    reader = PdfReader(file_path)
                    for page in reader.pages:
                        text += page.extract_text() + "\n"
                
                # TXT ve Markdown Ä°ÅŸleme
                elif filename.endswith((".txt", ".md")):
                    with open(file_path, "r", encoding="utf-8") as f:
                        text = f.read()

                # DOCX (Word) Ä°ÅŸleme
                elif filename.endswith(".docx"):
                    doc = Document(file_path)
                    text = "\n".join([para.text for para in doc.paragraphs])

                # Excel ve CSV Ä°ÅŸleme (Tablosal)
                elif filename.endswith((".csv", ".xlsx", ".xls")):
                    if filename.endswith(".csv"):
                        df = pd.read_csv(file_path)
                    else:
                        df = pd.read_excel(file_path)
                    
                    # Her satÄ±rÄ± bir metin parÃ§asÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
                    rows_text = []
                    for idx, row in df.iterrows():
                        row_str = ", ".join([f"{col}: {row[col]}" for col in df.columns])
                        rows_text.append(row_str)
                    text = "\n".join(rows_text)
                
                if text.strip():
                    chunks = self.splitter.split_text(text)
                    all_texts.extend(chunks)
                    all_metadata.extend([{"source": filename}] * len(chunks))
                    logger.info(f"[+] Ä°ÅŸlendi: {filename} ({len(chunks)} parÃ§a)")

            except Exception as e:
                logger.error(f"[X] {filename} iÅŸlenirken hata: {e}")

        if all_texts:
            self.vector.add_texts(all_texts, all_metadata)
            logger.info(f"[!] {len(all_texts)} parÃ§a ile Bilgi KÃ¼pÃ¼ gÃ¼ncellendi.")

    async def ask_question(self, question: str) -> str:
        """KullanÄ±cÄ±nÄ±n sorusunu dÃ¶kÃ¼manlara gÃ¶re yanÄ±tlar."""
        try:
            # 1. Benzer metin parÃ§alarÄ±nÄ± bul (threshold ile filtrele)
            context_docs = self.model_search_context(question)
            
            if not context_docs:
                logger.info(f"[i] Soru iÃ§in dÃ¶kÃ¼manlarda eÅŸleÅŸme bulunamadÄ±: {question}")
                return "ÃœzgÃ¼nÃ¼m, bilgi kÃ¼pÃ¼mde bu soruyla eÅŸleÅŸen herhangi bir dÃ¶kÃ¼man veya bilgi bulunamadÄ±. ğŸ˜”"

            # 2. BaÄŸlamÄ± (Context) hazÄ±rla
            context_text = "\n\n".join([
                f"--- Kaynak: {doc['metadata'].get('source', 'Bilinmiyor')} ---\n{doc['text']}" 
                for doc in context_docs
            ])

            # 3. LLM'e (Groq) sor - SÄ±kÄ± Kurallar AltÄ±nda
            system_prompt = (
                "Sen Cemil'sin, sadece sana verilen dÃ¶kÃ¼manlara (BAÄLAM) dayanarak cevap veren bir asistansÄ±n. "
                "Åu kurallara KESÄ°NLÄ°KLE uy:\n"
                "1. Sadece sana verilen BAÄLAM iÃ§indeki bilgileri kullan.\n"
                "2. BaÄŸlam dÄ±ÅŸÄ±ndaki genel kÃ¼ltÃ¼rÃ¼nÃ¼ veya dÄ±ÅŸ bilgileri KESÄ°NLÄ°KLE kullanma.\n"
                "3. EÄŸer cevabÄ± baÄŸlamda aÃ§Ä±kÃ§a gÃ¶remiyorsan, tahmin yÃ¼rÃ¼tme; 'Bu konuda dÃ¶kÃ¼manlarÄ±mda bilgi bulamadÄ±m' de.\n"
                "4. CevabÄ± uydurma, manipÃ¼le etme veya varsayÄ±mlarda bulunma.\n"
                "5. YanÄ±tlarÄ±nda hiÃ§bir emoji veya ASCII olmayan karakter kullanma (sadece ASCII).\n"
                "6. YanÄ±tlarÄ±n Ã¶z, net ve samimi olsun."
            )
            
            user_prompt = f"BAÄLAM:\n{context_text}\n\nSORU: {question}"
            
            answer = await self.groq.quick_ask(system_prompt, user_prompt)
            
            # 4. KaynaklarÄ± Ekle
            unique_sources = list(set([doc['metadata'].get('source', 'Bilinmiyor') for doc in context_docs]))
            if unique_sources:
                answer += f"\n\n[Kaynaklar: {', '.join(unique_sources)}]"
            
            return answer

        except Exception as e:
            logger.error(f"[X] KnowledgeService.ask_question hatasÄ±: {e}")
            return "Åu an hafÄ±zamÄ± toparlamakta zorlanÄ±yorum, birazdan tekrar sorar mÄ±sÄ±n? ğŸ§ âœ¨"

    def model_search_context(self, question: str) -> List[Dict]:
        """VektÃ¶r veritabanÄ±ndan baÄŸlamÄ± Ã§eker."""
        return self.vector.search(question, top_k=4, threshold=0.6)
